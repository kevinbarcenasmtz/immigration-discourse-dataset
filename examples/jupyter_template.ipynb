{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Immigration Corpus - Jupyter Notebook Template\n",
    "\n",
    "Quick start template for analyzing immigration discourse data.\n",
    "\n",
    "**Before running:** Make sure you've installed the library:\n",
    "```bash\n",
    "pip install git+https://github.com/kevinbarcenasmtz/immigration-discourse-dataset.git\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. AWS Credentials Setup\n",
    "\n",
    "Choose ONE of these options:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option A: AWS CLI (recommended - if you ran `aws configure`)\n",
    "\n",
    "If you've already run `aws configure` in terminal, skip to Section 2. No setup needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option B: Set credentials in notebook (quick but less secure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: Don't commit this notebook with credentials!\n",
    "# Add *.ipynb to .gitignore if needed\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'PASTE-YOUR-KEY-HERE'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'PASTE-YOUR-SECRET-HERE'\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option C: Prompt for credentials (most secure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will prompt you to paste credentials (input hidden)\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = getpass('AWS Access Key ID: ')\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = getpass('AWS Secret Access Key: ')\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n",
    "\n",
    "print('âœ… Credentials set!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from immigration_corpus import (\n",
    "    load_data,\n",
    "    search_term,\n",
    "    get_term_counts,\n",
    "    filter_by_date,\n",
    "    filter_by_source,\n",
    "    get_stats,\n",
    "    export_to_json\n",
    ")\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Notebook settings\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load first 3 files (~19K articles)\n",
    "# Adjust files=[0, 1, 2] to load more/less\n",
    "df = load_data(files=[0, 1, 2])\n",
    "\n",
    "print(f\"\\nLoaded {len(df):,} articles\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset statistics\n",
    "stats = get_stats(df)\n",
    "\n",
    "print(f\"Total articles: {stats['total_articles']:,}\")\n",
    "print(f\"Unique sources: {stats['unique_sources']}\")\n",
    "print(f\"Date range: {stats['date_range'][0]} to {stats['date_range'][1]}\")\n",
    "print(f\"\\nTop 5 sources:\")\n",
    "for source, count in list(stats['top_sources'].items())[:5]:\n",
    "    print(f\"  {source}: {count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize source distribution\n",
    "top_sources = pd.Series(stats['top_sources']).head(10)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_sources.plot(kind='barh')\n",
    "plt.xlabel('Number of Articles')\n",
    "plt.title('Top 10 News Sources')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Term Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare terminology usage\n",
    "terms = ['illegal alien', 'undocumented immigrant']\n",
    "counts = get_term_counts(df, terms)\n",
    "\n",
    "for term, stats in counts.items():\n",
    "    print(f\"{term}: {stats['count']:,} articles ({stats['percentage']:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize term comparison\n",
    "term_data = pd.DataFrame({\n",
    "    'Term': list(counts.keys()),\n",
    "    'Count': [counts[t]['count'] for t in counts.keys()]\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.bar(term_data['Term'], term_data['Count'])\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.title('Immigration Terminology Comparison')\n",
    "plt.xticks(rotation=15)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Filter and Analyze by Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare conservative vs liberal sources\n",
    "conservative = filter_by_source(df, ['breitbart.com', 'foxnews.com'])\n",
    "liberal = filter_by_source(df, ['huffpost.com', 'cnn.com'])\n",
    "\n",
    "print(f\"Conservative sources: {len(conservative):,} articles\")\n",
    "print(f\"Liberal sources: {len(liberal):,} articles\")\n",
    "\n",
    "# Compare term usage\n",
    "cons_counts = get_term_counts(conservative, terms)\n",
    "lib_counts = get_term_counts(liberal, terms)\n",
    "\n",
    "print(\"\\nConservative sources:\")\n",
    "for term in terms:\n",
    "    print(f\"  {term}: {cons_counts[term]['percentage']:.2f}%\")\n",
    "\n",
    "print(\"\\nLiberal sources:\")\n",
    "for term in terms:\n",
    "    print(f\"  {term}: {lib_counts[term]['percentage']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Your Analysis\n",
    "\n",
    "Add your custom analysis below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Export Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export filtered results for further analysis\n",
    "# results = search_term(df, 'illegal alien')\n",
    "# export_to_json(results, 'illegal_alien_articles.jsonl')\n",
    "# results.to_csv('my_analysis.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
